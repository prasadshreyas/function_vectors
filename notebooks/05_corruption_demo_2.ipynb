{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_shot vs n-trails?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "from tqdm import tqdm\n",
    "import torch, numpy as np\n",
    "import argparse\n",
    "from baukit import TraceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include prompt creation helper functions\n",
    "from utils.prompt_utils import *\n",
    "# from utils.intervention_utils import *\n",
    "from utils.model_utils import *\n",
    "# from utils.extract_utils import *\n",
    "from utils.intervention_utils import replace_activation_w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_replacement_per_class_intervention(prompt_data, avg_activations, dummy_labels, model, model_config, tokenizer, last_token_only=True):\n",
    "    \"\"\"\n",
    "    Experiment to determine top intervention locations through avg activation replacement. \n",
    "    Performs a systematic sweep over attention heads (layer, head) to track their causal influence on probs of key tokens.\n",
    "\n",
    "    Parameters: \n",
    "    prompt_data: dict containing ICL prompt examples, and template information\n",
    "    avg_activations: avg activation of each attention head in the model taken across n_trials ICL prompts\n",
    "    dummy_labels: labels and indices for a baseline prompt with the same number of example pairs\n",
    "    model: huggingface model\n",
    "    model_config: contains model config information (n layers, n heads, etc.)\n",
    "    tokenizer: huggingface tokenizer\n",
    "    last_token_only: If True, only computes indirect effect for heads at the final token position. If False, computes indirect_effect for heads for all token classes\n",
    "\n",
    "    Returns:   \n",
    "    indirect_effect_storage: torch tensor containing the indirect_effect of each head for each token class.\n",
    "    \"\"\"\n",
    "    device = model.device\n",
    "    print(\"---------------------------Activation Replacement--------------\")\n",
    "    print(f\"prompt_data: {prompt_data}\")\n",
    "    # Get sentence and token labels\n",
    "    query_target_pair = prompt_data['query_target']\n",
    "    print(\"query_target_pair:\", query_target_pair)\n",
    "    query = query_target_pair['input']\n",
    "    token_labels, prompt_string = get_token_meta_labels(prompt_data, tokenizer, query=query)\n",
    "    \n",
    "    print(\"token_labels is a list of triplet that contains (idx, token, meta_label)\")\n",
    "    print(f\"token_labels: {token_labels}\")\n",
    "    print(f\"prompt_string: {prompt_string}\")\n",
    "    \n",
    "    print(\"dummy_labels\", dummy_labels)\n",
    "    idx_map, idx_avg = compute_duplicated_labels(token_labels, dummy_labels)\n",
    "    print(\"idx_map\", idx_map)\n",
    "    print(\"idx_avg\", idx_avg)\n",
    "    \n",
    "    idx_map = update_idx_map(idx_map, idx_avg)\n",
    "    print(\"(updated)idx_avg\", idx_avg)\n",
    "      \n",
    "    sentences = [prompt_string]# * model.config.n_head # batch things by head\n",
    "\n",
    "    print(\"sentences\", sentences)\n",
    "\n",
    "    # Figure out tokens of interest\n",
    "    tokens_of_interest = [query_target_pair['output']]\n",
    "    print(\"tokens_of_interest\", tokens_of_interest)\n",
    "    \n",
    "    if 'llama' in model_config['name_or_path']:\n",
    "        ts = tokenizer(tokens_of_interest, return_tensors='pt').input_ids.squeeze()\n",
    "        if tokenizer.decode(ts[1])=='' or ts[1]==29871: # avoid spacing issues\n",
    "            token_id_of_interest = ts[2]\n",
    "        else:\n",
    "            token_id_of_interest = ts[1]\n",
    "    else:\n",
    "        token_id_of_interest = tokenizer(tokens_of_interest).input_ids[0][:1]\n",
    "        \n",
    "    inputs = tokenizer(sentences, return_tensors='pt').to(device)\n",
    "\n",
    "    # Speed up computation by only computing causal effect at last token\n",
    "    if last_token_only:\n",
    "        token_classes = ['query_predictive']\n",
    "        token_classes_regex = ['query_predictive_token']\n",
    "    # Compute causal effect for all token classes (instead of just last token)\n",
    "    else:\n",
    "        token_classes = ['demonstration', 'label', 'separator', 'predictive', 'structural','end_of_example', \n",
    "                        'query_demonstration', 'query_structural', 'query_separator', 'query_predictive']\n",
    "        token_classes_regex = ['demonstration_[\\d]{1,}_token', 'demonstration_[\\d]{1,}_label_token', 'separator_token', 'predictive_token', 'structural_token','end_of_example_token', \n",
    "                            'query_demonstration_token', 'query_structural_token', 'query_separator_token', 'query_predictive_token']\n",
    "    \n",
    "\n",
    "    indirect_effect_storage = torch.zeros(model_config['n_layers'], model_config['n_heads'],len(token_classes))\n",
    "    print(f\"indirect_effect_storage.shape: {indirect_effect_storage.shape}\")\n",
    "\n",
    "    # Clean Run of Baseline:\n",
    "    clean_output = model(**inputs).logits[:,-1,:]\n",
    "    print(f\"clean_output.shape: {clean_output.shape}\")\n",
    "    clean_probs = torch.softmax(clean_output[0], dim=-1)\n",
    "    print(f\"clean_probs.shape: {clean_probs.shape}\")\n",
    "\n",
    "    # For every layer, head, token combination perform the replacement & track the change in meaningful tokens\n",
    "    for layer in range(model_config['n_layers']):\n",
    "        head_hook_layer = [model_config['attn_hook_names'][layer]]\n",
    "        \n",
    "        for head_n in range(model_config['n_heads']):\n",
    "            for i,(token_class, class_regex) in enumerate(zip(token_classes, token_classes_regex)):\n",
    "                print(\"token_class, class_regex: \", token_class, class_regex)\n",
    "                reg_class_match = re.compile(f\"^{class_regex}$\")\n",
    "                print(\"reg_class_match: \", reg_class_match)\n",
    "                \n",
    "                class_token_inds = [x[0] for x in token_labels if reg_class_match.match(x[2])]\n",
    "                print(\"class_token_inds: \", class_token_inds)\n",
    "                \n",
    "\n",
    "                intervention_locations = [(layer, head_n, token_n) for token_n in class_token_inds]\n",
    "                print(\"intervention_locations:\", intervention_locations)\n",
    "                intervention_fn = replace_activation_w_avg(layer_head_token_pairs=intervention_locations, avg_activations=avg_activations, \n",
    "                                                           model=model, model_config=model_config,\n",
    "                                                           batched_input=False, idx_map=idx_map, last_token_only=last_token_only)\n",
    "                with TraceDict(model, layers=head_hook_layer, edit_output=intervention_fn) as td:                \n",
    "                    output = model(**inputs).logits[:,-1,:] # batch_size x n_tokens x vocab_size, only want last token prediction\n",
    "                \n",
    "                # TRACK probs of tokens of interest\n",
    "                intervention_probs = torch.softmax(output, dim=-1) # convert to probability distribution\n",
    "                indirect_effect_storage[layer,head_n,i] = (intervention_probs-clean_probs).index_select(1, torch.LongTensor(token_id_of_interest).to(device).squeeze()).squeeze()\n",
    "\n",
    "    return indirect_effect_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_indirect_effect(dataset, mean_activations, model, model_config, tokenizer, n_shots=10, n_trials=25, last_token_only=True, prefixes=None, separators=None, filter_set=None):\n",
    "    \"\"\"\n",
    "    Computes Indirect Effect of each head in the model\n",
    "    \"\"\"\n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    print(f\"Starting computation of indirect effects with {n_shots} shots and {n_trials} trials...\")\n",
    "    n_test_examples = 1\n",
    "\n",
    "    if prefixes is not None and separators is not None:\n",
    "        print(\"Using custom prefixes and separators for dummy token labels...\")\n",
    "        dummy_gt_labels = get_dummy_token_labels(n_shots, tokenizer=tokenizer, prefixes=prefixes, separators=separators)\n",
    "    else:\n",
    "        print(\"Using default settings for dummy token labels...\")\n",
    "        dummy_gt_labels = get_dummy_token_labels(n_shots, tokenizer=tokenizer)\n",
    "    \n",
    "    print(f\"Dummy ground truth labels generated with length: {len(dummy_gt_labels)}\")\n",
    "    print(f\" 10 Dummy ground truth labels are:{dummy_gt_labels[:10]}\")\n",
    "    \n",
    "    is_llama = 'llama' in model_config['name_or_path']\n",
    "    prepend_bos = not is_llama\n",
    "    print(f\"Model prepend_bos setting: {prepend_bos}\")\n",
    "\n",
    "    if last_token_only:\n",
    "        indirect_effect = torch.zeros(n_trials, model_config['n_layers'], model_config['n_heads'])\n",
    "    else:\n",
    "        indirect_effect = torch.zeros(n_trials, model_config['n_layers'], model_config['n_heads'], 10) # have 10 classes of tokens\n",
    "    \n",
    "    print(f\"Initialized indirect effect tensor with zero tensor of shape: {indirect_effect.shape}\")\n",
    "\n",
    "    if filter_set is None:\n",
    "        filter_set = np.arange(len(dataset['valid']))\n",
    "    \n",
    "    for i in tqdm(range(n_trials), total=n_trials):\n",
    "        word_pairs = dataset['train'][np.random.choice(len(dataset['train']), n_shots, replace=False)]\n",
    "        word_pairs_test = dataset['valid'][np.random.choice(filter_set, n_test_examples, replace=False)]\n",
    "        \n",
    "        print(f\"Trial {i+1}/{n_trials}: Selected word pairs for prompts and testing.\")\n",
    "\n",
    "        print(\"Parameters to word_pairs_to_prompt_data:\")\n",
    "        print(f\"word_pairs: {word_pairs}, query_target_pair: {word_pairs_test}, shuffle_labels: True, prepend_bos_token: {prepend_bos}\")\n",
    "\n",
    "        if prefixes is not None and separators is not None:\n",
    "            prompt_data_random = word_pairs_to_prompt_data(word_pairs, query_target_pair=word_pairs_test, shuffle_labels=True, \n",
    "                                                           prepend_bos_token=prepend_bos, prefixes=prefixes, separators=separators)\n",
    "        else:\n",
    "            prompt_data_random = word_pairs_to_prompt_data(word_pairs, query_target_pair=word_pairs_test, \n",
    "                                                           shuffle_labels=True, prepend_bos_token=prepend_bos)\n",
    "        print(f\"Generated prompt data for trial {i+1}.\")\n",
    "        print(\"Prompt Data\", prompt_data_random)\n",
    "        \n",
    "        ind_effects = activation_replacement_per_class_intervention(prompt_data=prompt_data_random, \n",
    "                                                                    avg_activations=mean_activations, \n",
    "                                                                    dummy_labels=dummy_gt_labels, \n",
    "                                                                    model=model, model_config=model_config, tokenizer=tokenizer, \n",
    "                                                                    last_token_only=last_token_only)\n",
    "        indirect_effect[i] = ind_effects.squeeze()\n",
    "        print(f\"Indirect effects calculated for trial {i+1} with shape: {ind_effects.shape}.\")\n",
    "\n",
    "    print(\"Completed computation of indirect effects.\")\n",
    "    return indirect_effect\n",
    "\n",
    "# Note: You'll need to define or adapt the functions get_dummy_token_labels and word_pairs_to_prompt_data,\n",
    "# as well as activation_replacement_per_class_intervention, according to their requirements and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = {\n",
    "    'dataset_name': 'antonym',\n",
    "    'model_name': 'gpt2',\n",
    "    'root_data_dir': '../dataset_files',\n",
    "    'save_path_root': '../results',\n",
    "    'seed': 42,\n",
    "    'n_shots': 10,\n",
    "    'n_trials': 1,\n",
    "    'test_split': 0.3,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'mean_activations_path': None,\n",
    "    'last_token_only': True,\n",
    "    'prefixes': {\"input\": \"Q:\", \"output\": \"A:\", \"instructions\": \"\"},\n",
    "    'separators': {\"input\": \"\\\\n\", \"output\": \"\\\\n\\\\n\", \"instructions\": \"\"}\n",
    "}\n",
    "\n",
    "dataset_name = args['dataset_name']\n",
    "model_name = args['model_name']\n",
    "root_data_dir = args['root_data_dir']\n",
    "save_path_root = f\"{args['save_path_root']}/{dataset_name}\"\n",
    "seed = args['seed']\n",
    "n_shots = args['n_shots']\n",
    "n_trials = args['n_trials']\n",
    "test_split = args['test_split']\n",
    "device = args['device']\n",
    "mean_activations_path = args['mean_activations_path']\n",
    "last_token_only = args['last_token_only']\n",
    "prefixes = args['prefixes']\n",
    "separators = args['separators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Loading:  gpt2\n"
     ]
    }
   ],
   "source": [
    "# Load Model & Tokenizer\n",
    "torch.set_grad_enabled(False)\n",
    "print(\"Loading Model\")\n",
    "model, tokenizer, model_config = load_gpt_model_and_tokenizer(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading Dataset\")\n",
    "dataset = load_dataset(dataset_name, root_data_dir=root_data_dir, test_size=test_split, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path_root):\n",
    "    os.makedirs(save_path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or Re-Compute Mean Activations\n",
    "if mean_activations_path is not None and os.path.exists(mean_activations_path):\n",
    "    mean_activations = torch.load(mean_activations_path)\n",
    "elif mean_activations_path is None and os.path.exists(f'{save_path_root}/{dataset_name}_mean_head_activations.pt'):\n",
    "    mean_activations_path = f'{save_path_root}/{dataset_name}_mean_head_activations.pt'\n",
    "    mean_activations = torch.load(mean_activations_path)        \n",
    "else:\n",
    "    print(\"Computing Mean Activations\")\n",
    "    mean_activations = get_mean_head_activations(dataset, model=model, model_config=model_config, tokenizer=tokenizer, \n",
    "                                                    n_icl_examples=n_shots, N_TRIALS=n_trials, prefixes=prefixes, separators=separators)\n",
    "    torch.save(mean_activations, f'{save_path_root}/{dataset_name}_mean_head_activations.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Indirect Effect\n",
      "---------------------------------------------------------------------\n",
      "Starting computation of indirect effects with 10 shots and 1 trials...\n",
      "Using custom prefixes and separators for dummy token labels...\n",
      "<function get_token_meta_labels at 0x2ba95b53dd80>\n",
      "----------------------------\n",
      "get_prompt_parts_and_labels\n",
      "----------------------------\n",
      "prompt_parts: ['<|endoftext|>', '', '', ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:', ' a', '\\\\n\\\\n'], ['Q:', ' a', '\\\\n', 'A:']]\n",
      "prompt_part_labels: ['bos_token', 'instructions_token', 'separator_token', ['structural_token', 'demonstration_1_token', 'separator_token', 'structural_token', 'demonstration_1_label_token', 'separator_token'], ['structural_token', 'demonstration_2_token', 'separator_token', 'structural_token', 'demonstration_2_label_token', 'separator_token'], ['structural_token', 'demonstration_3_token', 'separator_token', 'structural_token', 'demonstration_3_label_token', 'separator_token'], ['structural_token', 'demonstration_4_token', 'separator_token', 'structural_token', 'demonstration_4_label_token', 'separator_token'], ['structural_token', 'demonstration_5_token', 'separator_token', 'structural_token', 'demonstration_5_label_token', 'separator_token'], ['structural_token', 'demonstration_6_token', 'separator_token', 'structural_token', 'demonstration_6_label_token', 'separator_token'], ['structural_token', 'demonstration_7_token', 'separator_token', 'structural_token', 'demonstration_7_label_token', 'separator_token'], ['structural_token', 'demonstration_8_token', 'separator_token', 'structural_token', 'demonstration_8_label_token', 'separator_token'], ['structural_token', 'demonstration_9_token', 'separator_token', 'structural_token', 'demonstration_9_label_token', 'separator_token'], ['structural_token', 'demonstration_10_token', 'separator_token', 'structural_token', 'demonstration_10_label_token', 'separator_token'], ['query_structural_token', 'query_demonstration_token', 'query_separator_token', 'query_structural_token']]\n",
      "Dummy ground truth labels generated with length: 128\n",
      " 10 Dummy ground truth labels are:[(0, 'bos_token'), (1, 'structural_token'), (2, 'structural_token'), (3, 'demonstration_1_token'), (4, 'separator_token'), (5, 'separator_token'), (6, 'structural_token'), (7, 'predictive_token'), (8, 'demonstration_1_label_token'), (9, 'end_of_example_token')]\n",
      "Model prepend_bos setting: True\n",
      "Initialized indirect effect tensor with zero tensor of shape: torch.Size([1, 12, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/1: Selected word pairs for prompts and testing.\n",
      "Parameters to word_pairs_to_prompt_data:\n",
      "word_pairs: {'input': ['valley', 'economic', 'fugitive', 'inward', 'unmarked', 'worthless', 'regress', 'borrowing', 'saline', 'risky'], 'output': ['mountain', 'uneconomic', 'law-abiding citizen', 'outward', 'marked', 'valuable', 'progress', 'lending', 'freshwater', 'safe']}, query_target_pair: {'input': ['secure'], 'output': ['insecure']}, shuffle_labels: True, prepend_bos_token: True\n",
      "Generated prompt data for trial 1.\n",
      "Prompt Data {'instructions': '', 'separators': {'input': '\\\\n', 'output': '\\\\n\\\\n', 'instructions': ''}, 'prefixes': {'input': 'Q:', 'output': 'A:', 'instructions': '<|endoftext|>'}, 'query_target': {'input': ' secure', 'output': ' insecure'}, 'examples': [{'input': ' valley', 'output': ' progress'}, {'input': ' economic', 'output': ' valuable'}, {'input': ' fugitive', 'output': ' outward'}, {'input': ' inward', 'output': ' freshwater'}, {'input': ' unmarked', 'output': ' safe'}, {'input': ' worthless', 'output': ' mountain'}, {'input': ' regress', 'output': ' marked'}, {'input': ' borrowing', 'output': ' lending'}, {'input': ' saline', 'output': ' uneconomic'}, {'input': ' risky', 'output': ' law-abiding citizen'}]}\n",
      "---------------------------Activation Replacement--------------\n",
      "prompt_data: {'instructions': '', 'separators': {'input': '\\\\n', 'output': '\\\\n\\\\n', 'instructions': ''}, 'prefixes': {'input': 'Q:', 'output': 'A:', 'instructions': '<|endoftext|>'}, 'query_target': {'input': ' secure', 'output': ' insecure'}, 'examples': [{'input': ' valley', 'output': ' progress'}, {'input': ' economic', 'output': ' valuable'}, {'input': ' fugitive', 'output': ' outward'}, {'input': ' inward', 'output': ' freshwater'}, {'input': ' unmarked', 'output': ' safe'}, {'input': ' worthless', 'output': ' mountain'}, {'input': ' regress', 'output': ' marked'}, {'input': ' borrowing', 'output': ' lending'}, {'input': ' saline', 'output': ' uneconomic'}, {'input': ' risky', 'output': ' law-abiding citizen'}]}\n",
      "query_target_pair: {'input': ' secure', 'output': ' insecure'}\n",
      "<function get_token_meta_labels at 0x2ba95b53dd80>\n",
      "----------------------------\n",
      "get_prompt_parts_and_labels\n",
      "----------------------------\n",
      "prompt_parts: ['<|endoftext|>', '', '', ['Q:', ' valley', '\\\\n', 'A:', ' progress', '\\\\n\\\\n'], ['Q:', ' economic', '\\\\n', 'A:', ' valuable', '\\\\n\\\\n'], ['Q:', ' fugitive', '\\\\n', 'A:', ' outward', '\\\\n\\\\n'], ['Q:', ' inward', '\\\\n', 'A:', ' freshwater', '\\\\n\\\\n'], ['Q:', ' unmarked', '\\\\n', 'A:', ' safe', '\\\\n\\\\n'], ['Q:', ' worthless', '\\\\n', 'A:', ' mountain', '\\\\n\\\\n'], ['Q:', ' regress', '\\\\n', 'A:', ' marked', '\\\\n\\\\n'], ['Q:', ' borrowing', '\\\\n', 'A:', ' lending', '\\\\n\\\\n'], ['Q:', ' saline', '\\\\n', 'A:', ' uneconomic', '\\\\n\\\\n'], ['Q:', ' risky', '\\\\n', 'A:', ' law-abiding citizen', '\\\\n\\\\n'], ['Q:', ' secure', '\\\\n', 'A:']]\n",
      "prompt_part_labels: ['bos_token', 'instructions_token', 'separator_token', ['structural_token', 'demonstration_1_token', 'separator_token', 'structural_token', 'demonstration_1_label_token', 'separator_token'], ['structural_token', 'demonstration_2_token', 'separator_token', 'structural_token', 'demonstration_2_label_token', 'separator_token'], ['structural_token', 'demonstration_3_token', 'separator_token', 'structural_token', 'demonstration_3_label_token', 'separator_token'], ['structural_token', 'demonstration_4_token', 'separator_token', 'structural_token', 'demonstration_4_label_token', 'separator_token'], ['structural_token', 'demonstration_5_token', 'separator_token', 'structural_token', 'demonstration_5_label_token', 'separator_token'], ['structural_token', 'demonstration_6_token', 'separator_token', 'structural_token', 'demonstration_6_label_token', 'separator_token'], ['structural_token', 'demonstration_7_token', 'separator_token', 'structural_token', 'demonstration_7_label_token', 'separator_token'], ['structural_token', 'demonstration_8_token', 'separator_token', 'structural_token', 'demonstration_8_label_token', 'separator_token'], ['structural_token', 'demonstration_9_token', 'separator_token', 'structural_token', 'demonstration_9_label_token', 'separator_token'], ['structural_token', 'demonstration_10_token', 'separator_token', 'structural_token', 'demonstration_10_label_token', 'separator_token'], ['query_structural_token', 'query_demonstration_token', 'query_separator_token', 'query_structural_token']]\n",
      "token_labels is a list of triplet that contains (idx, token, meta_label)\n",
      "token_labels: [(0, '<|endoftext|>', 'bos_token'), (1, 'Q', 'structural_token'), (2, ':', 'structural_token'), (3, ' valley', 'demonstration_1_token'), (4, '\\\\', 'separator_token'), (5, 'n', 'separator_token'), (6, 'A', 'structural_token'), (7, ':', 'predictive_token'), (8, ' progress', 'demonstration_1_label_token'), (9, '\\\\', 'end_of_example_token'), (10, 'n', 'separator_token'), (11, '\\\\', 'separator_token'), (12, 'n', 'separator_token'), (13, 'Q', 'structural_token'), (14, ':', 'structural_token'), (15, ' economic', 'demonstration_2_token'), (16, '\\\\', 'separator_token'), (17, 'n', 'separator_token'), (18, 'A', 'structural_token'), (19, ':', 'predictive_token'), (20, ' valuable', 'demonstration_2_label_token'), (21, '\\\\', 'end_of_example_token'), (22, 'n', 'separator_token'), (23, '\\\\', 'separator_token'), (24, 'n', 'separator_token'), (25, 'Q', 'structural_token'), (26, ':', 'structural_token'), (27, ' fugitive', 'demonstration_3_token'), (28, '\\\\', 'separator_token'), (29, 'n', 'separator_token'), (30, 'A', 'structural_token'), (31, ':', 'predictive_token'), (32, ' outward', 'demonstration_3_label_token'), (33, '\\\\', 'end_of_example_token'), (34, 'n', 'separator_token'), (35, '\\\\', 'separator_token'), (36, 'n', 'separator_token'), (37, 'Q', 'structural_token'), (38, ':', 'structural_token'), (39, ' inward', 'demonstration_4_token'), (40, '\\\\', 'separator_token'), (41, 'n', 'separator_token'), (42, 'A', 'structural_token'), (43, ':', 'predictive_token'), (44, ' freshwater', 'demonstration_4_label_token'), (45, '\\\\', 'end_of_example_token'), (46, 'n', 'separator_token'), (47, '\\\\', 'separator_token'), (48, 'n', 'separator_token'), (49, 'Q', 'structural_token'), (50, ':', 'structural_token'), (51, ' unmarked', 'demonstration_5_token'), (52, '\\\\', 'separator_token'), (53, 'n', 'separator_token'), (54, 'A', 'structural_token'), (55, ':', 'predictive_token'), (56, ' safe', 'demonstration_5_label_token'), (57, '\\\\', 'end_of_example_token'), (58, 'n', 'separator_token'), (59, '\\\\', 'separator_token'), (60, 'n', 'separator_token'), (61, 'Q', 'structural_token'), (62, ':', 'structural_token'), (63, ' worthless', 'demonstration_6_token'), (64, '\\\\', 'separator_token'), (65, 'n', 'separator_token'), (66, 'A', 'structural_token'), (67, ':', 'predictive_token'), (68, ' mountain', 'demonstration_6_label_token'), (69, '\\\\', 'end_of_example_token'), (70, 'n', 'separator_token'), (71, '\\\\', 'separator_token'), (72, 'n', 'separator_token'), (73, 'Q', 'structural_token'), (74, ':', 'structural_token'), (75, ' regress', 'demonstration_7_token'), (76, '\\\\', 'separator_token'), (77, 'n', 'separator_token'), (78, 'A', 'structural_token'), (79, ':', 'predictive_token'), (80, ' marked', 'demonstration_7_label_token'), (81, '\\\\', 'end_of_example_token'), (82, 'n', 'separator_token'), (83, '\\\\', 'separator_token'), (84, 'n', 'separator_token'), (85, 'Q', 'structural_token'), (86, ':', 'structural_token'), (87, ' borrowing', 'demonstration_8_token'), (88, '\\\\', 'separator_token'), (89, 'n', 'separator_token'), (90, 'A', 'structural_token'), (91, ':', 'predictive_token'), (92, ' lending', 'demonstration_8_label_token'), (93, '\\\\', 'end_of_example_token'), (94, 'n', 'separator_token'), (95, '\\\\', 'separator_token'), (96, 'n', 'separator_token'), (97, 'Q', 'structural_token'), (98, ':', 'structural_token'), (99, ' saline', 'demonstration_9_token'), (100, '\\\\', 'separator_token'), (101, 'n', 'separator_token'), (102, 'A', 'structural_token'), (103, ':', 'predictive_token'), (104, ' un', 'demonstration_9_label_token'), (105, 'economic', 'demonstration_9_label_token'), (106, '\\\\', 'end_of_example_token'), (107, 'n', 'separator_token'), (108, '\\\\', 'separator_token'), (109, 'n', 'separator_token'), (110, 'Q', 'structural_token'), (111, ':', 'structural_token'), (112, ' risky', 'demonstration_10_token'), (113, '\\\\', 'separator_token'), (114, 'n', 'separator_token'), (115, 'A', 'structural_token'), (116, ':', 'predictive_token'), (117, ' law', 'demonstration_10_label_token'), (118, '-', 'demonstration_10_label_token'), (119, 'abiding', 'demonstration_10_label_token'), (120, ' citizen', 'demonstration_10_label_token'), (121, '\\\\', 'end_of_example_token'), (122, 'n', 'separator_token'), (123, '\\\\', 'separator_token'), (124, 'n', 'separator_token'), (125, 'Q', 'query_structural_token'), (126, ':', 'query_structural_token'), (127, ' secure', 'query_demonstration_token'), (128, '\\\\', 'query_separator_token'), (129, 'n', 'query_separator_token'), (130, 'A', 'query_structural_token'), (131, ':', 'query_predictive_token')]\n",
      "prompt_string: <|endoftext|>Q: valley\\nA: progress\\n\\nQ: economic\\nA: valuable\\n\\nQ: fugitive\\nA: outward\\n\\nQ: inward\\nA: freshwater\\n\\nQ: unmarked\\nA: safe\\n\\nQ: worthless\\nA: mountain\\n\\nQ: regress\\nA: marked\\n\\nQ: borrowing\\nA: lending\\n\\nQ: saline\\nA: uneconomic\\n\\nQ: risky\\nA: law-abiding citizen\\n\\nQ: secure\\nA:\n",
      "dummy_labels [(0, 'bos_token'), (1, 'structural_token'), (2, 'structural_token'), (3, 'demonstration_1_token'), (4, 'separator_token'), (5, 'separator_token'), (6, 'structural_token'), (7, 'predictive_token'), (8, 'demonstration_1_label_token'), (9, 'end_of_example_token'), (10, 'separator_token'), (11, 'separator_token'), (12, 'separator_token'), (13, 'structural_token'), (14, 'structural_token'), (15, 'demonstration_2_token'), (16, 'separator_token'), (17, 'separator_token'), (18, 'structural_token'), (19, 'predictive_token'), (20, 'demonstration_2_label_token'), (21, 'end_of_example_token'), (22, 'separator_token'), (23, 'separator_token'), (24, 'separator_token'), (25, 'structural_token'), (26, 'structural_token'), (27, 'demonstration_3_token'), (28, 'separator_token'), (29, 'separator_token'), (30, 'structural_token'), (31, 'predictive_token'), (32, 'demonstration_3_label_token'), (33, 'end_of_example_token'), (34, 'separator_token'), (35, 'separator_token'), (36, 'separator_token'), (37, 'structural_token'), (38, 'structural_token'), (39, 'demonstration_4_token'), (40, 'separator_token'), (41, 'separator_token'), (42, 'structural_token'), (43, 'predictive_token'), (44, 'demonstration_4_label_token'), (45, 'end_of_example_token'), (46, 'separator_token'), (47, 'separator_token'), (48, 'separator_token'), (49, 'structural_token'), (50, 'structural_token'), (51, 'demonstration_5_token'), (52, 'separator_token'), (53, 'separator_token'), (54, 'structural_token'), (55, 'predictive_token'), (56, 'demonstration_5_label_token'), (57, 'end_of_example_token'), (58, 'separator_token'), (59, 'separator_token'), (60, 'separator_token'), (61, 'structural_token'), (62, 'structural_token'), (63, 'demonstration_6_token'), (64, 'separator_token'), (65, 'separator_token'), (66, 'structural_token'), (67, 'predictive_token'), (68, 'demonstration_6_label_token'), (69, 'end_of_example_token'), (70, 'separator_token'), (71, 'separator_token'), (72, 'separator_token'), (73, 'structural_token'), (74, 'structural_token'), (75, 'demonstration_7_token'), (76, 'separator_token'), (77, 'separator_token'), (78, 'structural_token'), (79, 'predictive_token'), (80, 'demonstration_7_label_token'), (81, 'end_of_example_token'), (82, 'separator_token'), (83, 'separator_token'), (84, 'separator_token'), (85, 'structural_token'), (86, 'structural_token'), (87, 'demonstration_8_token'), (88, 'separator_token'), (89, 'separator_token'), (90, 'structural_token'), (91, 'predictive_token'), (92, 'demonstration_8_label_token'), (93, 'end_of_example_token'), (94, 'separator_token'), (95, 'separator_token'), (96, 'separator_token'), (97, 'structural_token'), (98, 'structural_token'), (99, 'demonstration_9_token'), (100, 'separator_token'), (101, 'separator_token'), (102, 'structural_token'), (103, 'predictive_token'), (104, 'demonstration_9_label_token'), (105, 'end_of_example_token'), (106, 'separator_token'), (107, 'separator_token'), (108, 'separator_token'), (109, 'structural_token'), (110, 'structural_token'), (111, 'demonstration_10_token'), (112, 'separator_token'), (113, 'separator_token'), (114, 'structural_token'), (115, 'predictive_token'), (116, 'demonstration_10_label_token'), (117, 'end_of_example_token'), (118, 'separator_token'), (119, 'separator_token'), (120, 'separator_token'), (121, 'query_structural_token'), (122, 'query_structural_token'), (123, 'query_demonstration_token'), (124, 'query_separator_token'), (125, 'query_separator_token'), (126, 'query_structural_token'), (127, 'query_predictive_token')]\n",
      "Check indices: [(3, ' valley', 'demonstration_1_token'), (8, ' progress', 'demonstration_1_label_token'), (15, ' economic', 'demonstration_2_token'), (20, ' valuable', 'demonstration_2_label_token'), (27, ' fugitive', 'demonstration_3_token'), (32, ' outward', 'demonstration_3_label_token'), (39, ' inward', 'demonstration_4_token'), (44, ' freshwater', 'demonstration_4_label_token'), (51, ' unmarked', 'demonstration_5_token'), (56, ' safe', 'demonstration_5_label_token'), (63, ' worthless', 'demonstration_6_token'), (68, ' mountain', 'demonstration_6_label_token'), (75, ' regress', 'demonstration_7_token'), (80, ' marked', 'demonstration_7_label_token'), (87, ' borrowing', 'demonstration_8_token'), (92, ' lending', 'demonstration_8_label_token'), (99, ' saline', 'demonstration_9_token'), (104, ' un', 'demonstration_9_label_token'), (105, 'economic', 'demonstration_9_label_token'), (112, ' risky', 'demonstration_10_token'), (117, ' law', 'demonstration_10_label_token'), (118, '-', 'demonstration_10_label_token'), (119, 'abiding', 'demonstration_10_label_token'), (120, ' citizen', 'demonstration_10_label_token'), (127, ' secure', 'query_demonstration_token')]\n",
      "Duplicate Ranges: 2\n",
      "demonstration_10_label_token    (117, 120)\n",
      "demonstration_10_token          (112, 112)\n",
      "demonstration_1_label_token         (8, 8)\n",
      "demonstration_1_token               (3, 3)\n",
      "demonstration_2_label_token       (20, 20)\n",
      "demonstration_2_token             (15, 15)\n",
      "demonstration_3_label_token       (32, 32)\n",
      "demonstration_3_token             (27, 27)\n",
      "demonstration_4_label_token       (44, 44)\n",
      "demonstration_4_token             (39, 39)\n",
      "demonstration_5_label_token       (56, 56)\n",
      "demonstration_5_token             (51, 51)\n",
      "demonstration_6_label_token       (68, 68)\n",
      "demonstration_6_token             (63, 63)\n",
      "demonstration_7_label_token       (80, 80)\n",
      "demonstration_7_token             (75, 75)\n",
      "demonstration_8_label_token       (92, 92)\n",
      "demonstration_8_token             (87, 87)\n",
      "demonstration_9_label_token     (104, 105)\n",
      "demonstration_9_token             (99, 99)\n",
      "query_demonstration_token       (127, 127)\n",
      "Name: 0, dtype: object\n",
      "Duplicate Labels: ['demonstration_10_label_token', 'demonstration_9_label_token']\n",
      "Duplicate Label Ranges: {'demonstration_10_label_token': (117, 120), 'demonstration_9_label_token': (104, 105)}\n",
      "Duplicate Indices: [105 118 119 120]\n",
      "Index Map: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45, 46: 46, 47: 47, 48: 48, 49: 49, 50: 50, 51: 51, 52: 52, 53: 53, 54: 54, 55: 55, 56: 56, 57: 57, 58: 58, 59: 59, 60: 60, 61: 61, 62: 62, 63: 63, 64: 64, 65: 65, 66: 66, 67: 67, 68: 68, 69: 69, 70: 70, 71: 71, 72: 72, 73: 73, 74: 74, 75: 75, 76: 76, 77: 77, 78: 78, 79: 79, 80: 80, 81: 81, 82: 82, 83: 83, 84: 84, 85: 85, 86: 86, 87: 87, 88: 88, 89: 89, 90: 90, 91: 91, 92: 92, 93: 93, 94: 94, 95: 95, 96: 96, 97: 97, 98: 98, 99: 99, 100: 100, 101: 101, 102: 102, 103: 103, 104: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 121: 117, 122: 118, 123: 119, 124: 120, 125: 121, 126: 122, 127: 123, 128: 124, 129: 125, 130: 126, 131: 127}\n",
      "idx_map {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45, 46: 46, 47: 47, 48: 48, 49: 49, 50: 50, 51: 51, 52: 52, 53: 53, 54: 54, 55: 55, 56: 56, 57: 57, 58: 58, 59: 59, 60: 60, 61: 61, 62: 62, 63: 63, 64: 64, 65: 65, 66: 66, 67: 67, 68: 68, 69: 69, 70: 70, 71: 71, 72: 72, 73: 73, 74: 74, 75: 75, 76: 76, 77: 77, 78: 78, 79: 79, 80: 80, 81: 81, 82: 82, 83: 83, 84: 84, 85: 85, 86: 86, 87: 87, 88: 88, 89: 89, 90: 90, 91: 91, 92: 92, 93: 93, 94: 94, 95: 95, 96: 96, 97: 97, 98: 98, 99: 99, 100: 100, 101: 101, 102: 102, 103: 103, 104: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 121: 117, 122: 118, 123: 119, 124: 120, 125: 121, 126: 122, 127: 123, 128: 124, 129: 125, 130: 126, 131: 127}\n",
      "idx_avg {'demonstration_10_label_token': (117, 120), 'demonstration_9_label_token': (104, 105)}\n",
      "(updated)idx_avg {'demonstration_10_label_token': (117, 120), 'demonstration_9_label_token': (104, 105)}\n",
      "sentences ['<|endoftext|>Q: valley\\\\nA: progress\\\\n\\\\nQ: economic\\\\nA: valuable\\\\n\\\\nQ: fugitive\\\\nA: outward\\\\n\\\\nQ: inward\\\\nA: freshwater\\\\n\\\\nQ: unmarked\\\\nA: safe\\\\n\\\\nQ: worthless\\\\nA: mountain\\\\n\\\\nQ: regress\\\\nA: marked\\\\n\\\\nQ: borrowing\\\\nA: lending\\\\n\\\\nQ: saline\\\\nA: uneconomic\\\\n\\\\nQ: risky\\\\nA: law-abiding citizen\\\\n\\\\nQ: secure\\\\nA:']\n",
      "tokens_of_interest [' insecure']\n",
      "indirect_effect_storage.shape: torch.Size([12, 12, 1])\n",
      "clean_output.shape: torch.Size([1, 50257])\n",
      "clean_probs.shape: torch.Size([50257])\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(0, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.0.attn.c_proj\n",
      "Current layer index: 0\n",
      "Intervening in layer: 0\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 0: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(1, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.1.attn.c_proj\n",
      "Current layer index: 1\n",
      "Intervening in layer: 1\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 1: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(2, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.2.attn.c_proj\n",
      "Current layer index: 2\n",
      "Intervening in layer: 2\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 2: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(3, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.3.attn.c_proj\n",
      "Current layer index: 3\n",
      "Intervening in layer: 3\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 3: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(4, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.4.attn.c_proj\n",
      "Current layer index: 4\n",
      "Intervening in layer: 4\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 4: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(5, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.5.attn.c_proj\n",
      "Current layer index: 5\n",
      "Intervening in layer: 5\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 5: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(6, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.6.attn.c_proj\n",
      "Current layer index: 6\n",
      "Intervening in layer: 6\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 6: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(7, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.7.attn.c_proj\n",
      "Current layer index: 7\n",
      "Intervening in layer: 7\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 7: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(8, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.8.attn.c_proj\n",
      "Current layer index: 8\n",
      "Intervening in layer: 8\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 8: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(9, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.9.attn.c_proj\n",
      "Current layer index: 9\n",
      "Intervening in layer: 9\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 9: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(10, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.10.attn.c_proj\n",
      "Current layer index: 10\n",
      "Intervening in layer: 10\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 10: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 0, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 0, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 1, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 1, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 2, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 2, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 3, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 3, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 4, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 4, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 5, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 5, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 6, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 6, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 7, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 7, token 131\n",
      "GPT2 model detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:02<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 8, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 8, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 9, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 9, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 10, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 10, token 131\n",
      "GPT2 model detected\n",
      "token_class, class_regex:  query_predictive query_predictive_token\n",
      "reg_class_match:  re.compile('^query_predictive_token$')\n",
      "class_token_inds:  [131]\n",
      "intervention_locations: [(11, 11, 131)]\n",
      "----------------replace_activation_w_avg-------------\n",
      "Current layer name: transformer.h.11.attn.c_proj\n",
      "Current layer index: 11\n",
      "Intervening in layer: 11\n",
      "Inputs are a tuple, taking the first element\n",
      "Original input shape: torch.Size([1, 132, 768])\n",
      "New input shape after reshaping for heads: torch.Size([1, 132, 12, 64])\n",
      "Last token only mode\n",
      "Layer 11: Patching activation at last token for head 11, token 131\n",
      "GPT2 model detected\n",
      "Indirect effects calculated for trial 1 with shape: torch.Size([12, 12, 1]).\n",
      "Completed computation of indirect effects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing Indirect Effect\")\n",
    "indirect_effect = compute_indirect_effect(dataset, mean_activations, model=model, model_config=model_config, tokenizer=tokenizer, \n",
    "                                            n_shots=n_shots, n_trials=n_trials, last_token_only=last_token_only, prefixes=prefixes, separators=separators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
