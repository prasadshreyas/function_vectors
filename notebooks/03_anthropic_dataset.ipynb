{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x2ba1722abdf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Anthropic/discrim-eval\", 'explicit')\n",
    "\n",
    "# dataset = load_dataset(\"starmpcc/Asclepius-Synthetic-Clinical-Notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[(df['decision_question_id'] == 0) & (df['age'] == 20) & (df['gender'] == 'female')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filled_template</th>\n",
       "      <th>decision_question_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>fill_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The patient is a 20-year-old white female suff...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The patient is a 20-year-old Black female suff...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Black</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The patient is a 20-year-old Asian female suff...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The patient is a 20-year-old Hispanic female s...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The patient is a 20-year-old Native American f...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Native American</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filled_template  decision_question_id  \\\n",
       "0  The patient is a 20-year-old white female suff...                     0   \n",
       "1  The patient is a 20-year-old Black female suff...                     0   \n",
       "2  The patient is a 20-year-old Asian female suff...                     0   \n",
       "3  The patient is a 20-year-old Hispanic female s...                     0   \n",
       "4  The patient is a 20-year-old Native American f...                     0   \n",
       "\n",
       "    age  gender             race fill_type  \n",
       "0  20.0  female            white  explicit  \n",
       "1  20.0  female            Black  explicit  \n",
       "2  20.0  female            Asian  explicit  \n",
       "3  20.0  female         Hispanic  explicit  \n",
       "4  20.0  female  Native American  explicit  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test_df.iloc[0]['filled_template']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get the mean activations now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = 'gpt2'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\"n_heads\":model.config.n_head,\n",
    "                \"n_layers\":model.config.n_layer,\n",
    "                \"resid_dim\":model.config.n_embd,\n",
    "                \"name_or_path\":model.config.name_or_path,\n",
    "                \"attn_hook_names\":[f'transformer.h.{layer}.attn.c_proj' for layer in range(model.config.n_layer)],\n",
    "                \"layer_hook_names\":[f'transformer.h.{layer}' for layer in range(model.config.n_layer)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt').to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  464,  5827,   318,   257,  1160,    12,  1941,    12,   727,  2330,\n",
       "          4048,  7195,   422,  6049, 21919,  4369,    13,  1375,   468,   587,\n",
       "           319,  5980,  3097,   329,   625,   257,   614,   475,   607,  1535,\n",
       "           318, 18080,    13,  1375,   468,   587, 14451,   351,   257, 21919,\n",
       "         17052,   351,   257,   845,  1969, 16217,  2770,  2872,    13,   383,\n",
       "          5827,   338,   584,  1535, 21337,   389,  4143,   922,    11,   996,\n",
       "           607, 22456,   318,  4622,  2440,   621,  7306,    13,  1375,   468,\n",
       "          1913,  1641,  1104,    11,   468, 11238,  9216,    11,   290,   468,\n",
       "          9141,   477,  2672, 21951, 10991,    13,   220,  2102,    11, 41395,\n",
       "           329, 23319,   389, 18549,   290,   612,   318,   257,   890,  4953,\n",
       "          1351,    13,  1318,   318,   691,   257,  5969,   640,  4324,   284,\n",
       "           466,   262, 23319,   706,   262, 21919,  4329,  1695,   878,   340,\n",
       "           481,   645,  2392,   307, 13971,    13, 11259,   262,  3967, 21337,\n",
       "           286,   262,  5827,   338,  7901,   284,   607,  1535,   290,   262,\n",
       "          1969, 17052,  2872,    11,   815,   428,  1862,  5827,   307, 19086,\n",
       "          1143,   284,  3328,   428, 21919, 23319,    30]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import TraceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model_config['attn_hook_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer.h.0.attn.c_proj',\n",
       " 'transformer.h.1.attn.c_proj',\n",
       " 'transformer.h.2.attn.c_proj',\n",
       " 'transformer.h.3.attn.c_proj',\n",
       " 'transformer.h.4.attn.c_proj',\n",
       " 'transformer.h.5.attn.c_proj',\n",
       " 'transformer.h.6.attn.c_proj',\n",
       " 'transformer.h.7.attn.c_proj',\n",
       " 'transformer.h.8.attn.c_proj',\n",
       " 'transformer.h.9.attn.c_proj',\n",
       " 'transformer.h.10.attn.c_proj',\n",
       " 'transformer.h.11.attn.c_proj']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Activations \n",
    "with TraceDict(model, layers=layers, retain_input=True, retain_output=False) as td:                \n",
    "    model(**inputs) # batch_size x n_tokens x vocab_size, only want last token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TraceDict([('transformer.h.0.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395fc10>),\n",
       "           ('transformer.h.1.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395f8e0>),\n",
       "           ('transformer.h.2.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395e7a0>),\n",
       "           ('transformer.h.3.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395d720>),\n",
       "           ('transformer.h.4.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395e830>),\n",
       "           ('transformer.h.5.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395f580>),\n",
       "           ('transformer.h.6.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395db70>),\n",
       "           ('transformer.h.7.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395e380>),\n",
       "           ('transformer.h.8.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395fbe0>),\n",
       "           ('transformer.h.9.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395f0a0>),\n",
       "           ('transformer.h.10.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae96395fe50>),\n",
       "           ('transformer.h.11.attn.c_proj',\n",
       "            <baukit.nethook.Trace at 0x2ae963a08100>)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_activations_by_head(activations, model_config):\n",
    "    new_shape = activations.size()[:-1] + (model_config['n_heads'], model_config['resid_dim']//model_config['n_heads']) # split by head: + (n_attn_heads, hidden_size/n_attn_heads)\n",
    "    activations = activations.view(*new_shape)  # (batch_size, n_tokens, n_heads, head_hidden_dim)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_initial = torch.vstack([split_activations_by_head(td[layer].input, model_config) for layer in model_config['attn_hook_names']]).permute(0,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 12, 157, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_initial.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
